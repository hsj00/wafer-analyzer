# app.py
# ì›¨ì´í¼ ë§µ ë¶„ì„ê¸° â€” Streamlit Community Cloud ë°°í¬ìš©
# ì‹¤í–‰: streamlit run app.py
#
# [Cloud ë°°í¬ ì£¼ìš” ë³€ê²½ì ]
# â‘  í´ë” ë¸Œë¼ìš°ì €(tkinter/subprocess) ì œê±° â†’ st.file_uploader ì‚¬ìš©
# â‘¡ core.pyì— ê³µìœ  í•¨ìˆ˜ ë¶„ë¦¬ â†’ ìˆœí™˜ import í•´ê²°
# â‘¢ folder_picker_helper.py ì œê±° (Cloudì—ì„œ tkinter ì‚¬ìš© ë¶ˆê°€)
# â‘£ ìƒ˜í”Œ ë°ì´í„° ìƒì„±: tempfile ì‚¬ìš© â†’ BytesIOë¡œ ë©”ëª¨ë¦¬ì—ì„œ ì²˜ë¦¬
# â‘¤ ë¹„êµ ëª¨ë“œ: ë¡œì»¬ íŒŒì¼ â†’ ì—…ë¡œë“œ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½
# =============================================================================

# â”€â”€ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import io
import os
import time

# â”€â”€ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st

# â”€â”€ í•µì‹¬ í•¨ìˆ˜ (core.pyì—ì„œ import) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from core import (
    get_wafer_grid,
    add_wafer_outline,
    _wafer_layout,
    create_2d_heatmap,
    create_contour_map,
    create_3d_surface,
    create_line_scan,
    calculate_stats,
    apply_col_mapping,
    _default_col_index,
    load_file_cached,
    get_sheet_names,
)

# =============================================================================
# ì‹ ê·œ ëª¨ë“ˆ import (graceful degradation)
# =============================================================================
try:
    from modules.multi_param import render_multi_param_tab
    MULTI_PARAM_AVAILABLE = True
except ImportError:
    MULTI_PARAM_AVAILABLE = False

try:
    from modules.defect_overlay import render_defect_tab
    DEFECT_AVAILABLE = True
except ImportError:
    DEFECT_AVAILABLE = False

try:
    from modules.gpc import render_gpc_tab
    GPC_AVAILABLE = True
except ImportError:
    GPC_AVAILABLE = False

try:
    from modules.report import render_report_tab
    REPORT_AVAILABLE = True
except ImportError:
    REPORT_AVAILABLE = False

try:
    from modules.ml_anomaly import render_anomaly_tab
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False


# =============================================================================
# [1] í˜ì´ì§€ ì„¤ì •
# =============================================================================
st.set_page_config(page_title="ì›¨ì´í¼ ë§µ ë¶„ì„ê¸°", layout="wide")


# =============================================================================
# [2] íŒŒì¼ ì—…ë¡œë“œ í—¬í¼ (Cloud ì „ìš© â€” ë¡œì»¬ í´ë” ë¸Œë¼ìš°ì € ëŒ€ì²´)
# =============================================================================

def _save_uploaded_file(uploaded_file) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥í•˜ê³  ê²½ë¡œ ë°˜í™˜."""
    import tempfile
    tmp_dir = os.path.join(tempfile.gettempdir(), "wafer_data")
    os.makedirs(tmp_dir, exist_ok=True)
    path = os.path.join(tmp_dir, uploaded_file.name)
    with open(path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return path


def _generate_sample_data() -> dict[str, pd.DataFrame]:
    """ìƒ˜í”Œ ì›¨ì´í¼ ë°ì´í„° 5ê°œ ìƒì„± (ë©”ëª¨ë¦¬ ë‚´)."""
    samples = {}
    for idx in range(1, 6):
        np.random.seed(idx * 7)
        n, R = 400, 100
        r_pts = np.sqrt(np.random.uniform(0, 1, n)) * R * 0.95
        t_pts = np.random.uniform(0, 2 * np.pi, n)
        x_pts = r_pts * np.cos(t_pts)
        y_pts = r_pts * np.sin(t_pts)
        cx, cy = np.random.uniform(-25, 25), np.random.uniform(-25, 25)
        vals = (500 + idx * 8
                + 35 * np.exp(-((x_pts-cx)**2 + (y_pts-cy)**2) / (2*38**2))
                - 10 * np.exp(-((x_pts+cx)**2 + (y_pts+cy)**2) / (2*20**2))
                + np.random.normal(0, idx * 1.5, n))
        samples[f"wafer_{idx:02d}.csv"] = pd.DataFrame({
            "x": x_pts, "y": y_pts, "data": vals
        })
    return samples


# =============================================================================
# [3] UI í—¬í¼ í•¨ìˆ˜
# =============================================================================

def wafer_title_banner(fname: str, prefix: str = "") -> None:
    """í¸ì§‘ ê°€ëŠ¥í•œ íŒŒë€ ì œëª© ë°°ë„ˆ."""
    key = f"title_{prefix}{fname}"
    if key not in st.session_state:
        st.session_state[key] = os.path.splitext(fname)[0]

    new_title = st.text_input(
        "ì œëª©",
        value=st.session_state[key],
        key=f"input_{prefix}{fname}",
        label_visibility="collapsed"
    )
    st.session_state[key] = new_title

    st.markdown(
        f"<div style='text-align:center;padding:7px;background:#1a6bbf;"
        f"color:white;border-radius:7px;font-size:14px;font-weight:bold;"
        f"margin-bottom:6px;'>ğŸ“Š {new_title}</div>",
        unsafe_allow_html=True
    )


# =============================================================================
# [4] ë°ì´í„°ì…‹ ê´€ë¦¬ í•¨ìˆ˜ (ë¹„êµ ëª¨ë“œìš©)
# =============================================================================

def dataset_id() -> str:
    """ë°ì´í„°ì…‹ ê³ ìœ  ID ìƒì„±."""
    return f"ds_{time.time_ns()}"


def render_dataset_manager() -> None:
    """ì‚¬ì´ë“œë°”: ë°ì´í„°ì…‹ ëª©ë¡ + ìˆœì„œ ë³€ê²½(â–²/â–¼) + ì‚­ì œ(âœ•)."""
    datasets = st.session_state.get("datasets", [])
    if not datasets:
        st.sidebar.info("ë°ì´í„°ì…‹ ì—†ìŒ. ì•„ë˜ì—ì„œ ì¶”ê°€í•˜ì„¸ìš”.")
        return

    st.sidebar.markdown("---")
    st.sidebar.markdown("**ğŸ“‹ ë°ì´í„°ì…‹ ëª©ë¡**")

    for i, ds in enumerate(datasets):
        ds_id = ds["id"]
        c_name, c_up, c_dn, c_del = st.sidebar.columns([5, 1, 1, 1])

        label = ds["name"] if len(ds["name"]) <= 16 else ds["name"][:14] + "â€¦"
        c_name.markdown(
            f"<div style='padding-top:5px;font-size:11px;'>"
            f"<b>{i+1}.</b> {label}</div>",
            unsafe_allow_html=True
        )

        if c_up.button("â–²", key=f"dsup_{ds_id}", disabled=(i == 0)):
            datasets[i], datasets[i-1] = datasets[i-1], datasets[i]
            st.session_state.datasets = datasets
            st.rerun()

        if c_dn.button("â–¼", key=f"dsdn_{ds_id}", disabled=(i == len(datasets)-1)):
            datasets[i], datasets[i+1] = datasets[i+1], datasets[i]
            st.session_state.datasets = datasets
            st.rerun()

        if c_del.button("âœ•", key=f"dsdel_{ds_id}"):
            st.session_state.datasets.pop(i)
            st.rerun()


def render_dataset_creator_cloud() -> None:
    """ì‚¬ì´ë“œë°”: ì—…ë¡œë“œ íŒŒì¼ â†’ X/Y/Data ì»¬ëŸ¼ ì„ íƒ â†’ ë°ì´í„°ì…‹ ì¶”ê°€ (Cloudìš©)."""
    st.sidebar.markdown("---")
    st.sidebar.subheader("â• ë°ì´í„°ì…‹ ì¶”ê°€")

    uploaded = st.sidebar.file_uploader(
        "íŒŒì¼ ì—…ë¡œë“œ",
        type=["csv", "xlsx", "xls"],
        key="dc_file_uploader",
    )

    if uploaded is None:
        st.sidebar.info("CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return

    try:
        if uploaded.name.lower().endswith(".csv"):
            df_preview = pd.read_csv(uploaded)
            sel_sheet = None
        else:
            xf = pd.ExcelFile(uploaded)
            sheets = xf.sheet_names
            sel_sheet = st.sidebar.selectbox("ì‹œíŠ¸", sheets, key="dc_sheet")
            df_preview = pd.read_excel(uploaded, sheet_name=sel_sheet)
        all_cols = df_preview.columns.tolist()
    except Exception:
        st.sidebar.error("âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨")
        return

    def_x = _default_col_index(all_cols, "x",    0)
    def_y = _default_col_index(all_cols, "y",    1)
    def_d = _default_col_index(all_cols, "data", 2)

    x_col    = st.sidebar.selectbox("X ì»¬ëŸ¼",    all_cols, index=def_x, key="dc_x")
    y_col    = st.sidebar.selectbox("Y ì»¬ëŸ¼",    all_cols, index=def_y, key="dc_y")
    data_col = st.sidebar.selectbox("Data ì»¬ëŸ¼", all_cols, index=def_d, key="dc_d")

    sheet_tag = f"[{sel_sheet}]" if sel_sheet else ""
    auto_name = f"{os.path.splitext(uploaded.name)[0]}{sheet_tag} Â· {data_col}"
    ds_name   = st.sidebar.text_input("ë°ì´í„°ì…‹ ì´ë¦„", value=auto_name, key="dc_name")

    if st.sidebar.button("âœ… ë°ì´í„°ì…‹ ì¶”ê°€", type="primary",
                          use_container_width=True, key="dc_add"):
        if "datasets" not in st.session_state:
            st.session_state.datasets = []

        df_mapped = apply_col_mapping(df_preview, x_col, y_col, data_col)
        new_ds = {
            "id":       dataset_id(),
            "name":     ds_name,
            "df_json":  df_mapped.to_json(),
            "x_col":    x_col,
            "y_col":    y_col,
            "data_col": data_col,
        }
        st.session_state.datasets.append(new_ds)
        st.rerun()


def render_compare_card_cloud(ds: dict, resolution: int, colorscale: str,
                              n_contours: int, show_points: bool,
                              global_zmin, global_zmax) -> None:
    """ë°ì´í„°ì…‹ 1ê°œë¥¼ ë¹„êµ ì¹´ë“œ 1ê°œë¡œ ë Œë”ë§ (Cloudìš© â€” df_json ì§ì ‘ ì‚¬ìš©)."""
    ds_id = ds["id"]

    title_key = f"title_{ds_id}"
    if title_key not in st.session_state:
        st.session_state[title_key] = ds["name"]

    new_title = st.text_input(
        "ì´ë¦„",
        value=st.session_state[title_key],
        key=f"input_{ds_id}",
        label_visibility="collapsed"
    )
    st.session_state[title_key] = new_title
    st.markdown(
        f"<div style='text-align:center;padding:7px;background:#1a6bbf;"
        f"color:white;border-radius:7px;font-size:13px;font-weight:bold;"
        f"margin-bottom:6px;'>ğŸ“Š {new_title}</div>",
        unsafe_allow_html=True
    )

    try:
        df_json = ds["df_json"]

        fig = create_contour_map(
            df_json, resolution, colorscale, n_contours, show_points,
            compact=True, zmin=global_zmin, zmax=global_zmax
        )
        st.plotly_chart(fig, use_container_width=True)

        stats    = calculate_stats(df_json)
        stats_df = pd.DataFrame.from_dict(stats, orient="index", columns=["ê°’"])
        stats_df.index.name = "í•­ëª©"
        st.dataframe(stats_df, use_container_width=True)

    except Exception as e:
        st.error(f"âŒ {e}")


# =============================================================================
# [5] íƒ­ ê³µí†µ ê°€ë“œ í—¬í¼
# =============================================================================

def _check_module_available(available: bool, module_name: str) -> bool:
    """ëª¨ë“ˆ import ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•˜ê³  False ë°˜í™˜."""
    if not available:
        st.error(
            f"âš ï¸ **{module_name} ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**\n\n"
            f"`modules/{module_name.lower().replace(' ', '_')}.py` íŒŒì¼ì´ "
            f"`modules/` í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n\n"
            f"í•„ìš” íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ë„ í™•ì¸í•˜ì„¸ìš”:\n"
            f"```\npip install scikit-learn openpyxl kaleido\n```"
        )
        return False
    return True


def _check_shared_data() -> bool:
    """shared_df_jsonì´ Noneì´ë©´ ë¡œë“œ ì•ˆë‚´ ë©”ì‹œì§€."""
    if st.session_state.get("shared_df_json") is None:
        st.info(
            "â„¹ï¸ **ë¨¼ì € 'ğŸ“Š ì›¨ì´í¼ ë§µ' íƒ­ì—ì„œ íŒŒì¼ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.**\n\n"
            "ì›¨ì´í¼ ë§µ íƒ­ì„ ë°©ë¬¸í•˜ë©´ ë°ì´í„°ê°€ ìë™ìœ¼ë¡œ ì´ íƒ­ì—ë„ ê³µìœ ë©ë‹ˆë‹¤."
        )
        return False
    return True


# =============================================================================
# [6] ë©”ì¸ ì•±
# =============================================================================
st.title("ğŸ”¬ ì›¨ì´í¼ ë§µ ë¶„ì„ê¸°")
st.markdown("---")

# â”€â”€ SIDEBAR: ë°ì´í„° ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("ğŸ“ ë°ì´í„° ê´€ë¦¬")

# â”€â”€ íŒŒì¼ ì—…ë¡œë“œ (Cloud ì „ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
uploaded_files = st.sidebar.file_uploader(
    "ì›¨ì´í¼ ë°ì´í„° íŒŒì¼",
    type=["csv", "xlsx", "xls"],
    accept_multiple_files=True,
    key="main_uploader",
    help="CSV ë˜ëŠ” Excel íŒŒì¼ì„ 1ê°œ ì´ìƒ ì—…ë¡œë“œí•˜ì„¸ìš”.",
)

# â”€â”€ ì—…ë¡œë“œ íŒŒì¼ì„ session_stateì— ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "uploaded_dfs" not in st.session_state:
    st.session_state.uploaded_dfs = {}

for uf in uploaded_files:
    if uf.name not in st.session_state.uploaded_dfs:
        try:
            if uf.name.lower().endswith(".csv"):
                st.session_state.uploaded_dfs[uf.name] = pd.read_csv(uf)
            else:
                st.session_state.uploaded_dfs[uf.name] = pd.read_excel(uf)
        except Exception:
            st.sidebar.error(f"âŒ {uf.name} ì½ê¸° ì‹¤íŒ¨")

file_names = list(st.session_state.uploaded_dfs.keys())

# â”€â”€ ìƒ˜í”Œ ë°ì´í„° ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not file_names:
    st.sidebar.warning("âš ï¸ ì—…ë¡œë“œëœ íŒŒì¼ ì—†ìŒ")
    if st.sidebar.button("ğŸ¯ ìƒ˜í”Œ 5ê°œ ìƒì„±", type="primary"):
        samples = _generate_sample_data()
        st.session_state.uploaded_dfs.update(samples)
        st.rerun()

if not file_names and not st.session_state.uploaded_dfs:
    st.info(
        "ğŸ‘‹ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì›¨ì´í¼ ë°ì´í„° íŒŒì¼(CSV/Excel)ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ "
        "**ğŸ¯ ìƒ˜í”Œ 5ê°œ ìƒì„±** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”."
    )
    st.stop()

# ìƒ˜í”Œ ìƒì„± í›„ file_names ê°±ì‹ 
file_names = list(st.session_state.uploaded_dfs.keys())
if not file_names:
    st.stop()


# â”€â”€ SIDEBAR: ë¶„ì„ ëª¨ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.markdown("---")
st.sidebar.header("ğŸ”€ ë¶„ì„ ëª¨ë“œ")

compare_mode = st.sidebar.toggle("ë¹„êµ ëª¨ë“œ í™œì„±í™”", value=False)

if compare_mode:
    render_dataset_manager()
    render_dataset_creator_cloud()
    st.sidebar.markdown("---")
    cols_per_row = st.sidebar.radio(
        "í–‰ë‹¹ ë§µ ê°œìˆ˜", [2, 3, 4], index=1,
        horizontal=True, key="cpr_compare"
    )
    lock_scale = st.sidebar.checkbox(
        "ğŸ”’ ì»¬ëŸ¬ ìŠ¤ì¼€ì¼ í†µì¼", value=False, key="lock_scale_compare"
    )
else:
    selected_file = st.sidebar.selectbox("ë¶„ì„ íŒŒì¼ ì„ íƒ", file_names)

    # Excel ì‹œíŠ¸ ì²˜ë¦¬
    df_raw = st.session_state.uploaded_dfs[selected_file]
    selected_sheet = None  # ì—…ë¡œë“œ ì‹œ ì´ë¯¸ ì²« ì‹œíŠ¸ë¡œ ì½í˜”ìŒ

    current_key = (selected_file, selected_sheet)
    if st.session_state.get("_s_file") != current_key:
        st.session_state._s_file    = current_key
        st.session_state._s_display = None
        st.session_state._s_col_map = None
        for k in ["shared_df_json", "shared_stats", "shared_fig_heatmap",
                   "shared_fig_contour", "shared_fig_linescan", "shared_fig_3d",
                   "shared_df_raw", "shared_all_cols", "shared_wafer_radius",
                   "shared_filename"]:
            st.session_state[k] = None


# â”€â”€ SIDEBAR: ì‹œê°í™” ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.markdown("---")
st.sidebar.header("âš™ï¸ ì‹œê°í™” ì„¤ì •")

COLORSCALES = {
    "Rainbow":       "Rainbow",
    "RdYlBu (ë°˜ì „)": "RdYlBu_r",
    "Jet":           "Jet",
    "Hot":           "Hot",
    "Viridis":       "Viridis",
    "Plasma":        "Plasma",
    "Spectral":      "Spectral_r"
}
cs_name    = st.sidebar.selectbox("ì»¬ëŸ¬ ìŠ¤ì¼€ì¼", list(COLORSCALES.keys()), index=0)
colorscale = COLORSCALES[cs_name]

resolution  = st.sidebar.slider("í•´ìƒë„", 30, 200, 100, 10)
show_points = st.sidebar.checkbox("ë°ì´í„° í¬ì¸íŠ¸ í‘œì‹œ", value=False)
n_contours  = st.sidebar.slider("Contour ë‹¨ê³„ ìˆ˜", 5, 40, 20)
if not compare_mode:
    line_angle = st.sidebar.slider("Line Scan ê°ë„ (Â°)", 0, 175, 0, 5)


# =============================================================================
# [ë‹¨ì¼ ë¶„ì„ ëª¨ë“œ]
# =============================================================================
if not compare_mode:
    all_cols = df_raw.columns.tolist()

    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ”— ì»¬ëŸ¼ ë§¤í•‘")

    def_x = _default_col_index(all_cols, "x",    0)
    def_y = _default_col_index(all_cols, "y",    1)
    def_d = _default_col_index(all_cols, "data", 2)

    x_col    = st.sidebar.selectbox("X ì»¬ëŸ¼",    all_cols, index=def_x, key="s_xcol")
    y_col    = st.sidebar.selectbox("Y ì»¬ëŸ¼",    all_cols, index=def_y, key="s_ycol")
    data_col = st.sidebar.selectbox("Data ì»¬ëŸ¼", all_cols, index=def_d, key="s_dcol")

    col_key = f"{x_col}|{y_col}|{data_col}"
    if st.session_state.get("_s_col_map") != col_key or \
       st.session_state._s_display is None:
        st.session_state._s_col_map = col_key
        st.session_state._s_display = apply_col_mapping(df_raw, x_col, y_col, data_col)

    df_display = st.session_state._s_display
    df_json    = df_display.to_json()
    stats      = calculate_stats(df_json)

    # â”€â”€ ì°¨íŠ¸ ì‚¬ì „ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fig_heatmap  = create_2d_heatmap(df_json, resolution, colorscale, show_points)
    fig_contour  = create_contour_map(df_json, resolution, colorscale,
                                      n_contours, show_points)
    fig_linescan = create_line_scan(df_json, line_angle, resolution)
    fig_3d       = create_3d_surface(df_json, resolution, colorscale)

    _, _, _, wafer_radius = get_wafer_grid(df_json, resolution)

    # â”€â”€ íƒ­ ê°„ ê³µìœ  ë°ì´í„° ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.session_state["shared_df_json"]      = df_json
    st.session_state["shared_stats"]        = stats
    st.session_state["shared_fig_heatmap"]  = fig_heatmap
    st.session_state["shared_fig_contour"]  = fig_contour
    st.session_state["shared_fig_linescan"] = fig_linescan
    st.session_state["shared_fig_3d"]       = fig_3d
    st.session_state["shared_df_raw"]       = df_display
    st.session_state["shared_all_cols"]     = all_cols
    st.session_state["shared_wafer_radius"] = float(wafer_radius)
    st.session_state["shared_filename"]     = selected_file
    st.session_state["shared_raw_df_json"]  = df_raw.to_json()
    st.session_state["shared_df_raw_original"] = df_raw

    # â”€â”€ ì œëª© ë°°ë„ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    wafer_title_banner(selected_file, prefix="single_")

    # â”€â”€ íƒ­ ë ˆì´ë¸” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tab_labels = [
        "ğŸ“Š ì›¨ì´í¼ ë§µ",
        "ğŸ“ ë‹¤ì¤‘ íŒŒë¼ë¯¸í„°" + ("" if MULTI_PARAM_AVAILABLE else " âš ï¸"),
        "ğŸ” ê²°í•¨ ì˜¤ë²„ë ˆì´" + ("" if DEFECT_AVAILABLE      else " âš ï¸"),
        "âš—ï¸ GPC ë¶„ì„"      + ("" if GPC_AVAILABLE         else " âš ï¸"),
        "ğŸ“„ ë³´ê³ ì„œ ìƒì„±"   + ("" if REPORT_AVAILABLE      else " âš ï¸"),
        "ğŸ¤– ML ì´ìƒ íƒì§€"  + ("" if ML_AVAILABLE          else " âš ï¸"),
    ]

    (tab_wafer, tab_multi, tab_defect,
     tab_gpc, tab_report, tab_ml) = st.tabs(tab_labels)

    # =========================================================================
    # tab_wafer: ê¸°ì¡´ ë‹¨ì¼ ëª¨ë“œ ì‹œê°í™”
    # =========================================================================
    with tab_wafer:
        c1, c2, c3 = st.columns([5, 5, 2])
        with c1:
            st.markdown("#### 2D Wafer Map")
            st.plotly_chart(fig_heatmap, use_container_width=True)
        with c2:
            st.markdown("#### Contour Map")
            st.plotly_chart(fig_contour, use_container_width=True)
        with c3:
            st.markdown("### ğŸ“Š Statistics")
            for k, v in stats.items():
                st.markdown(f"**{k}**")
                st.code(str(v), language=None)

        c4, c5 = st.columns([2, 3])
        with c4:
            st.plotly_chart(fig_linescan, use_container_width=True)
        with c5:
            st.plotly_chart(fig_3d, use_container_width=True)

        st.markdown("---")
        st.subheader("ğŸ“‹ Raw Data (ì…€ í¸ì§‘ ì¦‰ì‹œ ë°˜ì˜)")
        edited_df = st.data_editor(
            df_display,
            num_rows="dynamic",
            key=f"single_editor_{selected_file}_{col_key}",
            column_config={
                "x":    st.column_config.NumberColumn("X (mm)",  format="%.2f"),
                "y":    st.column_config.NumberColumn("Y (mm)",  format="%.2f"),
                "data": st.column_config.NumberColumn("ì¸¡ì •ê°’",  format="%.3f")
            },
            use_container_width=True,
            hide_index=False
        )
        st.session_state._s_display = edited_df

        st.download_button(
            "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
            edited_df.to_csv(index=False),
            "wafer_export.csv",
            "text/csv"
        )

    # =========================================================================
    # tab_multi: ë‹¤ì¤‘ íŒŒë¼ë¯¸í„° ì„œë¸Œí”Œë¡¯
    # =========================================================================
    with tab_multi:
        if not _check_module_available(MULTI_PARAM_AVAILABLE, "multi_param"):
            pass
        elif not _check_shared_data():
            pass
        else:
            render_multi_param_tab(
                df_json=st.session_state["shared_raw_df_json"],
                all_cols=st.session_state["shared_all_cols"],
                resolution=resolution,
                colorscale=colorscale,
            )

    # =========================================================================
    # tab_defect: ê²°í•¨ ì˜¤ë²„ë ˆì´
    # =========================================================================
    with tab_defect:
        if not _check_module_available(DEFECT_AVAILABLE, "defect_overlay"):
            pass
        elif not _check_shared_data():
            pass
        else:
            render_defect_tab(
                wafer_df_json=st.session_state["shared_df_json"],
                wafer_radius=st.session_state["shared_wafer_radius"],
                resolution=resolution,
                colorscale=colorscale,
                data_folder="",  # Cloudì—ì„œëŠ” í´ë” ë¯¸ì‚¬ìš©
            )

    # =========================================================================
    # tab_gpc: GPC ë¶„ì„
    # =========================================================================
    with tab_gpc:
        if not _check_module_available(GPC_AVAILABLE, "gpc"):
            pass
        elif not _check_shared_data():
            pass
        else:
            render_gpc_tab(
                df_raw=st.session_state["shared_df_raw_original"],
                all_cols=st.session_state["shared_all_cols"],
                resolution=resolution,
                colorscale=colorscale,
            )

    # =========================================================================
    # tab_report: Excel ë³´ê³ ì„œ ìƒì„±
    # =========================================================================
    with tab_report:
        if not _check_module_available(REPORT_AVAILABLE, "report"):
            pass
        elif not _check_shared_data():
            pass
        else:
            gpc_data = st.session_state.get("gpc_result", None)
            render_report_tab(
                filename=st.session_state["shared_filename"],
                stats=st.session_state["shared_stats"],
                df_display=st.session_state["shared_df_raw"],
                fig_heatmap=st.session_state["shared_fig_heatmap"],
                fig_contour=st.session_state["shared_fig_contour"],
                fig_linescan=st.session_state["shared_fig_linescan"],
                fig_3d=st.session_state["shared_fig_3d"],
                gpc_data=gpc_data,
            )

    # =========================================================================
    # tab_ml: ML ì´ìƒ íƒì§€
    # =========================================================================
    with tab_ml:
        if not _check_module_available(ML_AVAILABLE, "ml_anomaly"):
            pass
        else:
            app_initial_datasets = []

            current_df_json  = st.session_state.get("shared_df_json")
            current_filename = st.session_state.get("shared_filename", "")
            if current_df_json is not None and current_filename:
                app_initial_datasets.append({
                    "name":    os.path.splitext(current_filename)[0],
                    "df_json": current_df_json,
                })

            for ds in st.session_state.get("datasets", []):
                if any(m["name"] == ds["name"] for m in app_initial_datasets):
                    continue
                if "df_json" in ds:
                    app_initial_datasets.append({
                        "name":    ds["name"],
                        "df_json": ds["df_json"],
                    })

            render_anomaly_tab(
                datasets=app_initial_datasets,
                resolution=resolution,
                data_folder="",
            )


# =============================================================================
# [ë¹„êµ ë¶„ì„ ëª¨ë“œ]
# =============================================================================
else:
    datasets = st.session_state.get("datasets", [])

    if len(datasets) < 2:
        st.warning("âš ï¸ ì‚¬ì´ë“œë°” í•˜ë‹¨ì—ì„œ ë°ì´í„°ì…‹ì„ 2ê°œ ì´ìƒ ì¶”ê°€í•˜ì„¸ìš”.")
        with st.expander("ğŸ’¡ ë°ì´í„°ì…‹ ì¶”ê°€ ë°©ë²•", expanded=True):
            st.markdown("""
            1. ì‚¬ì´ë“œë°” **â• ë°ì´í„°ì…‹ ì¶”ê°€** ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ
            2. X / Y / Data ì»¬ëŸ¼ ì§€ì •
            3. ì´ë¦„ ì„¤ì • í›„ **âœ… ë°ì´í„°ì…‹ ì¶”ê°€** í´ë¦­
            4. **ê°™ì€ íŒŒì¼ì—ì„œ ì—¬ëŸ¬ ë²ˆ ì¶”ê°€** ê°€ëŠ¥ (Data ì»¬ëŸ¼ë§Œ ë‹¤ë¥´ê²Œ)
            """)
        st.stop()

    n_sel = len(datasets)
    st.subheader(f"ğŸ”€ ë°ì´í„°ì…‹ ë¹„êµ â€” {n_sel}ê°œ")

    # â”€â”€ ì»¬ëŸ¬ ìŠ¤ì¼€ì¼ í†µì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    global_zmin, global_zmax = None, None
    if lock_scale:
        series_list = []
        for ds in datasets:
            try:
                df_tmp = pd.read_json(ds["df_json"])
                series_list.append(df_tmp["data"].dropna())
            except Exception:
                pass

        if series_list:
            all_vals = pd.concat(series_list, ignore_index=True)
            global_zmin = float(all_vals.min())
            global_zmax = float(all_vals.max())
            st.info(f"ğŸ”’ ìŠ¤ì¼€ì¼ ê³ ì •: {global_zmin:.2f} ~ {global_zmax:.2f}")

    # â”€â”€ cols_per_rowì”© ë¬¶ì–´ì„œ í–‰ ë‹¨ìœ„ ë Œë”ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for batch_start in range(0, n_sel, cols_per_row):
        batch = datasets[batch_start : batch_start + cols_per_row]
        cols  = st.columns(len(batch))
        for col, ds in zip(cols, batch):
            with col:
                render_compare_card_cloud(
                    ds, resolution, colorscale,
                    n_contours, show_points, global_zmin, global_zmax
                )
        if batch_start + cols_per_row < n_sel:
            st.markdown(
                "<hr style='border:1px solid #ddd;'>",
                unsafe_allow_html=True
            )
